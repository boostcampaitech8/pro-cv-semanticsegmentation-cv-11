# data 관련 설정
image_root: /data/ephemeral/home/pro-cv-semanticsegmentation-cv-11/data/train/DCM
label_root: /data/ephemeral/home/pro-cv-semanticsegmentation-cv-11/data/train/outputs_json

# 모델명 및 사전 학습 여부
model_name: Unet3PlusGN
model_parameter:
  n_classes: 29
  final_activation: null

# batch_size (4 or 2) 고정
train_batch_size: 1
val_batch_size: 1
accum_steps: 8   

# val_num_worker 지정
num_workers: 4

# image resize 2048로 고정
image_size: &image_size 512

# transform 관련
train_transform:
  Resize:
    width: *image_size
    height: *image_size
  
  # HorizontalFlip:
  #   p: 0.5

val_transform:
  Resize:
    width: *image_size
    height: *image_size

# 학습 관련 하이퍼파라미터
lr: 1e-3
weight_decay: 1e-6

max_epoch: &max_epoch 40

# loss 관련 설정
loss_name: Mixed

# 단일 loss 사용시에 필요한 parameter -> dict 형태로 작성
# loss_parameter: {}

# combo loss 사용시
loss_parameter:
  losses:
    - name: SoftBCEWithLogitsLoss
      weight: 0.3
      params: {}
    - name: DiceLoss
      weight: 0.7
      params:
        smooth: 1e-4

# scheduler 관련 설정
scheduler_name: CosineAnnealingWarmupRestarts

# scheduler 필요한 parameter -> dict 형태로 작성
# 1 cycle: 30 에폭 전체를 단일 사이클로 설정
# first_cycle_steps = warmup(320) + 29 에폭(9280) = 9600
scheduler_parameter:
  first_cycle_steps: 2240  # warmup(320) + 29 에폭(9280) = 30 에폭 (1 사이클)
  warmup_steps: 320  # 1 에폭 (320 steps)
  max_lr: 3e-3  # 초기 learning rate
  min_lr: 1e-6  # 최소 learning rate
  cycle_mult: 1.0  # 사이클 배수 (1.0이면 동일한 사이클 반복)
  gamma: 0.6  # 감쇠 계수 (1 사이클이므로 사용되지 않음)
# optimizer 관련 설정
optimizer_name: adamw

# random seed값
seed: 21

# validation 관련 인자 0번 폴드로 고정
val_fold: 0
val_interval: 2
threshold: 0.5

# checkpoint 저장 경로
save_dir: /data/ephemeral/home/pro-cv-semanticsegmentation-cv-11/checkpoints/unet3plusGN_512_acc8_bs1

# wandb
team_name: cv_11
project_name: cv-11-SEG
experiment_detail: unet3plusGN_512_acc8_bs1
# experiment_detail: 실험 detail 입력 # 숫자, 문자, -, _, . 만 가능 (space 불가)
